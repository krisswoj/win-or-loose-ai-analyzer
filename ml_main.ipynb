{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "%run biosignal_and_tetris_result_service.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = get_player_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E03_R02_S01\n",
      "E03_R02_S02\n",
      "E03_R02_S03\n"
     ]
    }
   ],
   "source": [
    "for key, value in results.items():\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results['E03_R02_S01'][0]['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Czas</th>\n",
       "      <th>A: BVP1</th>\n",
       "      <th>C: EMG1</th>\n",
       "      <th>E: Skin Cond</th>\n",
       "      <th>F: Temp1</th>\n",
       "      <th>G: Abd Resp</th>\n",
       "      <th>Draw</th>\n",
       "      <th>Lose</th>\n",
       "      <th>Win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.342</td>\n",
       "      <td>23.707</td>\n",
       "      <td>5.151</td>\n",
       "      <td>32.185</td>\n",
       "      <td>12.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2.003906</td>\n",
       "      <td>36.313</td>\n",
       "      <td>21.687</td>\n",
       "      <td>5.151</td>\n",
       "      <td>32.185</td>\n",
       "      <td>12.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2.007812</td>\n",
       "      <td>36.283</td>\n",
       "      <td>19.667</td>\n",
       "      <td>5.150</td>\n",
       "      <td>32.185</td>\n",
       "      <td>12.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2.011719</td>\n",
       "      <td>36.252</td>\n",
       "      <td>19.356</td>\n",
       "      <td>5.150</td>\n",
       "      <td>32.185</td>\n",
       "      <td>11.995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2.015625</td>\n",
       "      <td>36.219</td>\n",
       "      <td>20.651</td>\n",
       "      <td>5.149</td>\n",
       "      <td>32.185</td>\n",
       "      <td>11.991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>63.980469</td>\n",
       "      <td>39.719</td>\n",
       "      <td>9.931</td>\n",
       "      <td>5.984</td>\n",
       "      <td>31.911</td>\n",
       "      <td>13.265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16380</th>\n",
       "      <td>63.984375</td>\n",
       "      <td>39.700</td>\n",
       "      <td>10.656</td>\n",
       "      <td>5.984</td>\n",
       "      <td>31.911</td>\n",
       "      <td>13.266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>63.988281</td>\n",
       "      <td>39.671</td>\n",
       "      <td>13.659</td>\n",
       "      <td>5.984</td>\n",
       "      <td>31.911</td>\n",
       "      <td>13.267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>63.992188</td>\n",
       "      <td>39.633</td>\n",
       "      <td>16.715</td>\n",
       "      <td>5.984</td>\n",
       "      <td>31.911</td>\n",
       "      <td>13.268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16383</th>\n",
       "      <td>63.996094</td>\n",
       "      <td>39.587</td>\n",
       "      <td>17.906</td>\n",
       "      <td>5.983</td>\n",
       "      <td>31.911</td>\n",
       "      <td>13.269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15872 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Czas  A: BVP1  C: EMG1  E: Skin Cond  F: Temp1  G: Abd Resp  Draw  \\\n",
       "512     2.000000   36.342   23.707         5.151    32.185       12.010     1   \n",
       "513     2.003906   36.313   21.687         5.151    32.185       12.005     1   \n",
       "514     2.007812   36.283   19.667         5.150    32.185       12.000     1   \n",
       "515     2.011719   36.252   19.356         5.150    32.185       11.995     1   \n",
       "516     2.015625   36.219   20.651         5.149    32.185       11.991     1   \n",
       "...          ...      ...      ...           ...       ...          ...   ...   \n",
       "16379  63.980469   39.719    9.931         5.984    31.911       13.265     0   \n",
       "16380  63.984375   39.700   10.656         5.984    31.911       13.266     0   \n",
       "16381  63.988281   39.671   13.659         5.984    31.911       13.267     0   \n",
       "16382  63.992188   39.633   16.715         5.984    31.911       13.268     0   \n",
       "16383  63.996094   39.587   17.906         5.983    31.911       13.269     0   \n",
       "\n",
       "       Lose  Win  \n",
       "512       0    0  \n",
       "513       0    0  \n",
       "514       0    0  \n",
       "515       0    0  \n",
       "516       0    0  \n",
       "...     ...  ...  \n",
       "16379     1    0  \n",
       "16380     1    0  \n",
       "16381     1    0  \n",
       "16382     1    0  \n",
       "16383     1    0  \n",
       "\n",
       "[15872 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Czas','Draw','Lose','Win'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Lose'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Lose', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Lose',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(5,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8d59c02290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8d59c02290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 3.2074WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8d5e733560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8d5e733560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 2.4163 - val_loss: 0.8521\n",
      "Epoch 2/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.0879 - val_loss: 0.8424\n",
      "Epoch 3/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8709 - val_loss: 0.8287\n",
      "Epoch 4/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6336 - val_loss: 0.8205\n",
      "Epoch 5/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5367 - val_loss: 0.8132\n",
      "Epoch 6/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3878 - val_loss: 0.8071\n",
      "Epoch 7/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2465 - val_loss: 0.8010\n",
      "Epoch 8/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0496 - val_loss: 0.7933\n",
      "Epoch 9/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.7680\n",
      "Epoch 10/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8671 - val_loss: 0.7445\n",
      "Epoch 11/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8456 - val_loss: 0.7287\n",
      "Epoch 12/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8031 - val_loss: 0.7171\n",
      "Epoch 13/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7978 - val_loss: 0.7081\n",
      "Epoch 14/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.6990\n",
      "Epoch 15/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7805 - val_loss: 0.6900\n",
      "Epoch 16/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 0.6804\n",
      "Epoch 17/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7582 - val_loss: 0.6712\n",
      "Epoch 18/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7441 - val_loss: 0.6653\n",
      "Epoch 19/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7234 - val_loss: 0.6539\n",
      "Epoch 20/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7237 - val_loss: 0.6459\n",
      "Epoch 21/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7123 - val_loss: 0.6405\n",
      "Epoch 22/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7108 - val_loss: 0.6338\n",
      "Epoch 23/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7047 - val_loss: 0.6282\n",
      "Epoch 24/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7006 - val_loss: 0.6260\n",
      "Epoch 25/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7009 - val_loss: 0.6203\n",
      "Epoch 26/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6836 - val_loss: 0.6159\n",
      "Epoch 27/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6859 - val_loss: 0.6124\n",
      "Epoch 28/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6847 - val_loss: 0.6094\n",
      "Epoch 29/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6738 - val_loss: 0.6011\n",
      "Epoch 30/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6792 - val_loss: 0.6072\n",
      "Epoch 31/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6699 - val_loss: 0.5972\n",
      "Epoch 32/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6731 - val_loss: 0.5962\n",
      "Epoch 33/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.5947\n",
      "Epoch 34/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6669 - val_loss: 0.5963\n",
      "Epoch 35/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6576 - val_loss: 0.5876\n",
      "Epoch 36/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6582 - val_loss: 0.5866\n",
      "Epoch 37/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6669 - val_loss: 0.5840\n",
      "Epoch 38/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6519 - val_loss: 0.5810\n",
      "Epoch 39/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 0.5798\n",
      "Epoch 40/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6456 - val_loss: 0.5766\n",
      "Epoch 41/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.5736\n",
      "Epoch 42/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6515 - val_loss: 0.5671\n",
      "Epoch 43/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6572 - val_loss: 0.5639\n",
      "Epoch 44/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6398 - val_loss: 0.5629\n",
      "Epoch 45/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6514 - val_loss: 0.5884\n",
      "Epoch 46/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6462 - val_loss: 0.5793\n",
      "Epoch 47/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6353 - val_loss: 0.5597\n",
      "Epoch 48/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.5537\n",
      "Epoch 49/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6377 - val_loss: 0.5610\n",
      "Epoch 50/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 0.5529\n",
      "Epoch 51/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6308 - val_loss: 0.5543\n",
      "Epoch 52/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.5511\n",
      "Epoch 53/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 0.5461\n",
      "Epoch 54/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 0.5616\n",
      "Epoch 55/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.5460\n",
      "Epoch 56/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.5385\n",
      "Epoch 57/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.5345\n",
      "Epoch 58/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.5291\n",
      "Epoch 59/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5276\n",
      "Epoch 60/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.5339\n",
      "Epoch 61/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.5304\n",
      "Epoch 62/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 0.5167\n",
      "Epoch 63/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.5135\n",
      "Epoch 64/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 0.5065\n",
      "Epoch 65/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5843 - val_loss: 0.5041\n",
      "Epoch 66/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5772 - val_loss: 0.4981\n",
      "Epoch 67/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5856 - val_loss: 0.4898\n",
      "Epoch 68/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5774 - val_loss: 0.4930\n",
      "Epoch 69/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5665 - val_loss: 0.4824\n",
      "Epoch 70/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5711 - val_loss: 0.4794\n",
      "Epoch 71/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5580 - val_loss: 0.4759\n",
      "Epoch 72/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5559 - val_loss: 0.4646\n",
      "Epoch 73/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5594 - val_loss: 0.4688\n",
      "Epoch 74/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.4824\n",
      "Epoch 75/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5460 - val_loss: 0.4578\n",
      "Epoch 76/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 0.4477\n",
      "Epoch 77/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 0.4482\n",
      "Epoch 78/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5317 - val_loss: 0.4449\n",
      "Epoch 79/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5375 - val_loss: 0.4420\n",
      "Epoch 80/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5428 - val_loss: 0.4442\n",
      "Epoch 81/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5395 - val_loss: 0.4446\n",
      "Epoch 82/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5245 - val_loss: 0.4423\n",
      "Epoch 83/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5334 - val_loss: 0.4415\n",
      "Epoch 84/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5364 - val_loss: 0.4586\n",
      "Epoch 85/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5322 - val_loss: 0.4475\n",
      "Epoch 86/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5394 - val_loss: 0.4474\n",
      "Epoch 87/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5252 - val_loss: 0.4445\n",
      "Epoch 88/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5175 - val_loss: 0.4409\n",
      "Epoch 89/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5192 - val_loss: 0.4413\n",
      "Epoch 90/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5120 - val_loss: 0.4400\n",
      "Epoch 91/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.4803\n",
      "Epoch 92/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5481 - val_loss: 0.4714\n",
      "Epoch 93/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5358 - val_loss: 0.4526\n",
      "Epoch 94/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5287 - val_loss: 0.4453\n",
      "Epoch 95/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 0.4473\n",
      "Epoch 96/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5169 - val_loss: 0.4446\n",
      "Epoch 97/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5247 - val_loss: 0.4385\n",
      "Epoch 98/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5202 - val_loss: 0.4368\n",
      "Epoch 99/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5132 - val_loss: 0.4357\n",
      "Epoch 100/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5135 - val_loss: 0.4345\n",
      "Epoch 101/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5110 - val_loss: 0.4355\n",
      "Epoch 102/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5061 - val_loss: 0.4339\n",
      "Epoch 103/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5078 - val_loss: 0.4345\n",
      "Epoch 104/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4993 - val_loss: 0.4329\n",
      "Epoch 105/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5039 - val_loss: 0.4398\n",
      "Epoch 106/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.4353\n",
      "Epoch 107/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.4330\n",
      "Epoch 108/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5033 - val_loss: 0.4315\n",
      "Epoch 109/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.4321\n",
      "Epoch 110/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 0.4312\n",
      "Epoch 111/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5004 - val_loss: 0.4312\n",
      "Epoch 112/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.4333\n",
      "Epoch 113/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4994 - val_loss: 0.4319\n",
      "Epoch 114/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4964 - val_loss: 0.4307\n",
      "Epoch 115/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4939 - val_loss: 0.4304\n",
      "Epoch 116/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4965 - val_loss: 0.4316\n",
      "Epoch 117/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4973 - val_loss: 0.4337\n",
      "Epoch 118/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4955 - val_loss: 0.4305\n",
      "Epoch 119/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5002 - val_loss: 0.4301\n",
      "Epoch 120/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4978 - val_loss: 0.4293\n",
      "Epoch 121/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.4298\n",
      "Epoch 122/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.4298\n",
      "Epoch 123/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.4311\n",
      "Epoch 124/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.4337\n",
      "Epoch 125/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4929 - val_loss: 0.4297\n",
      "Epoch 126/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4915 - val_loss: 0.4288\n",
      "Epoch 127/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4917 - val_loss: 0.4282\n",
      "Epoch 128/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.4290\n",
      "Epoch 129/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.4278\n",
      "Epoch 130/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.4299\n",
      "Epoch 131/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4925 - val_loss: 0.4270\n",
      "Epoch 132/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4901 - val_loss: 0.4261\n",
      "Epoch 133/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4924 - val_loss: 0.4255\n",
      "Epoch 134/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4913 - val_loss: 0.4266\n",
      "Epoch 135/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4901 - val_loss: 0.4259\n",
      "Epoch 136/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4925 - val_loss: 0.4280\n",
      "Epoch 137/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4893 - val_loss: 0.4267\n",
      "Epoch 138/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4851 - val_loss: 0.4244\n",
      "Epoch 139/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.4257\n",
      "Epoch 140/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.4232\n",
      "Epoch 141/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4828 - val_loss: 0.4237\n",
      "Epoch 142/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4849 - val_loss: 0.4235\n",
      "Epoch 143/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4889 - val_loss: 0.4228\n",
      "Epoch 144/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4847 - val_loss: 0.4228\n",
      "Epoch 145/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4816 - val_loss: 0.4252\n",
      "Epoch 146/250\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4965 - val_loss: 0.4452\n",
      "Epoch 147/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5037 - val_loss: 0.4399\n",
      "Epoch 148/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5036 - val_loss: 0.4351\n",
      "Epoch 149/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4987 - val_loss: 0.4364\n",
      "Epoch 150/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.4355\n",
      "Epoch 151/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.4339\n",
      "Epoch 152/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.4326\n",
      "Epoch 153/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4906 - val_loss: 0.4318\n",
      "Epoch 154/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4914 - val_loss: 0.4296\n",
      "Epoch 155/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4860 - val_loss: 0.4284\n",
      "Epoch 156/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4838 - val_loss: 0.4262\n",
      "Epoch 157/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4832 - val_loss: 0.4250\n",
      "Epoch 158/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4776 - val_loss: 0.4238\n",
      "Epoch 159/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4263\n",
      "Epoch 160/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4745 - val_loss: 0.4252\n",
      "Epoch 161/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4769 - val_loss: 0.4226\n",
      "Epoch 162/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4725 - val_loss: 0.4208\n",
      "Epoch 163/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4824 - val_loss: 0.4210\n",
      "Epoch 164/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4836 - val_loss: 0.4310\n",
      "Epoch 165/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4835 - val_loss: 0.4266\n",
      "Epoch 166/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.4238\n",
      "Epoch 167/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.4218\n",
      "Epoch 168/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.4208\n",
      "Epoch 169/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.4223\n",
      "Epoch 170/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.4224\n",
      "Epoch 171/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.4215\n",
      "Epoch 172/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.4219\n",
      "Epoch 173/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.4205\n",
      "Epoch 174/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4750 - val_loss: 0.4207\n",
      "Epoch 175/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4722 - val_loss: 0.4201\n",
      "Epoch 176/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4709 - val_loss: 0.4197\n",
      "Epoch 177/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.4198\n",
      "Epoch 178/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4195\n",
      "Epoch 179/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.4191\n",
      "Epoch 180/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4690 - val_loss: 0.4197\n",
      "Epoch 181/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.4256\n",
      "Epoch 182/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.4249\n",
      "Epoch 183/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4767 - val_loss: 0.4239\n",
      "Epoch 184/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.4232\n",
      "Epoch 185/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4706 - val_loss: 0.4207\n",
      "Epoch 186/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4681 - val_loss: 0.4204\n",
      "Epoch 187/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4718 - val_loss: 0.4343\n",
      "Epoch 188/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5079 - val_loss: 0.4678\n",
      "Epoch 189/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 0.4537\n",
      "Epoch 190/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.4430\n",
      "Epoch 191/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.4384\n",
      "Epoch 192/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4983 - val_loss: 0.4372\n",
      "Epoch 193/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4891 - val_loss: 0.4374\n",
      "Epoch 194/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.4368\n",
      "Epoch 195/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.4350\n",
      "Epoch 196/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.4339\n",
      "Epoch 197/250\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4857 - val_loss: 0.4328\n",
      "Epoch 198/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4843 - val_loss: 0.4324\n",
      "Epoch 199/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4823 - val_loss: 0.4321\n",
      "Epoch 200/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4811 - val_loss: 0.4322\n",
      "Epoch 201/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4790 - val_loss: 0.4314\n",
      "Epoch 202/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4758 - val_loss: 0.4291\n",
      "Epoch 203/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4773 - val_loss: 0.4279\n",
      "Epoch 204/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4739 - val_loss: 0.4264\n",
      "Epoch 205/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4740 - val_loss: 0.4249\n",
      "Epoch 206/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4851 - val_loss: 0.4252\n",
      "Epoch 207/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4741 - val_loss: 0.4260\n",
      "Epoch 208/250\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4712 - val_loss: 0.4274\n",
      "Epoch 209/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4696 - val_loss: 0.4252\n",
      "Epoch 210/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4699 - val_loss: 0.4228\n",
      "Epoch 211/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4703 - val_loss: 0.4211\n",
      "Epoch 212/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4672 - val_loss: 0.4199\n",
      "Epoch 213/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4641 - val_loss: 0.4198\n",
      "Epoch 214/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4659 - val_loss: 0.4191\n",
      "Epoch 215/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4691 - val_loss: 0.4195\n",
      "Epoch 216/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4677 - val_loss: 0.4233\n",
      "Epoch 217/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4694 - val_loss: 0.4210\n",
      "Epoch 218/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4645 - val_loss: 0.4187\n",
      "Epoch 219/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4678 - val_loss: 0.4174\n",
      "Epoch 220/250\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4632 - val_loss: 0.4164\n",
      "Epoch 221/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4682 - val_loss: 0.4168\n",
      "Epoch 222/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4658 - val_loss: 0.4176\n",
      "Epoch 223/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4620 - val_loss: 0.4173\n",
      "Epoch 224/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.4159\n",
      "Epoch 225/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4594 - val_loss: 0.4162\n",
      "Epoch 226/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4621 - val_loss: 0.4167\n",
      "Epoch 227/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4633 - val_loss: 0.4163\n",
      "Epoch 228/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4626 - val_loss: 0.4155\n",
      "Epoch 229/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.4154\n",
      "Epoch 230/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4677 - val_loss: 0.4167\n",
      "Epoch 231/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4669 - val_loss: 0.4175\n",
      "Epoch 232/250\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4653 - val_loss: 0.4177\n",
      "Epoch 233/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4710 - val_loss: 0.4154\n",
      "Epoch 234/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4659 - val_loss: 0.4162\n",
      "Epoch 235/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4640 - val_loss: 0.4163\n",
      "Epoch 236/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4614 - val_loss: 0.4153\n",
      "Epoch 237/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4659 - val_loss: 0.4147\n",
      "Epoch 238/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.4148\n",
      "Epoch 239/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.4151\n",
      "Epoch 240/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4667 - val_loss: 0.4136\n",
      "Epoch 241/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4686 - val_loss: 0.4136\n",
      "Epoch 242/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4599 - val_loss: 0.4150\n",
      "Epoch 243/250\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4626 - val_loss: 0.4148\n",
      "Epoch 244/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4641 - val_loss: 0.4139\n",
      "Epoch 245/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4638 - val_loss: 0.4133\n",
      "Epoch 246/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4611 - val_loss: 0.4139\n",
      "Epoch 247/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4688 - val_loss: 0.4199\n",
      "Epoch 248/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4674 - val_loss: 0.4220\n",
      "Epoch 249/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4676 - val_loss: 0.4184\n",
      "Epoch 250/250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4621 - val_loss: 0.4149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d59be25d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=250,\n",
    "          batch_size=512,\n",
    "          validation_data=(X_test, y_test),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-bc83193b8b59>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f8d5aa61b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f8d5aa61b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      2292\n",
      "           1       0.96      0.61      0.75      2470\n",
      "\n",
      "    accuracy                           0.79      4762\n",
      "   macro avg       0.83      0.79      0.78      4762\n",
      "weighted avg       0.83      0.79      0.78      4762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2226,   66],\n",
       "       [ 956, 1514]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}